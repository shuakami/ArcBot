import asyncio
import json
import logging
from pathlib import Path
from typing import List, Dict, Any
import re

import socks
from telethon import TelegramClient

from llm_handler import LLMFilter

# ------------------- é…ç½® -------------------
logging.basicConfig(
    format='%(asctime)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

SCRIPT_DIR = Path(__file__).parent.resolve()
CONFIG_PATH = SCRIPT_DIR / "config.json"
SESSION_PATH = SCRIPT_DIR / "sessions"

# ------------------- ä¸»é€»è¾‘ -------------------
async def generate_prompts():
    """äº¤äº’å¼åœ°ä¸ºç”¨æˆ·ç”ŸæˆåŸºç¡€æŒ‡ä»¤å’Œåå¥½æç¤ºã€‚"""
    logger.info("ğŸš€ Starting Intelligent Prompt Generator...")
    
    # 1. åŠ è½½é…ç½®
    try:
        with open(CONFIG_PATH, "r", encoding="utf-8") as f:
            config = json.load(f)
    except FileNotFoundError:
        logger.error(f"âŒ é…ç½®æ–‡ä»¶ 'config.json' æœªæ‰¾åˆ°ã€‚")
        return

    api_id = config.get("api_id")
    api_hash = config.get("api_hash")
    phone_number = config.get("phone_number")
    channel_usernames = config.get("channel_usernames", [])
    proxy_cfg = config.get("proxy")

    if not all([api_id, api_hash, phone_number, channel_usernames]):
        logger.error("âŒ é…ç½®æ–‡ä»¶ä¸å®Œæ•´ï¼Œç¼ºå°‘ api_id, api_hash, phone_number æˆ– channel_usernamesã€‚")
        return

    llm_filter = LLMFilter(config)
    if not llm_filter.enabled:
        logger.error("âŒ LLM filter åœ¨ config.json ä¸­è¢«ç¦ç”¨ï¼Œæ— æ³•è¿›è¡ŒAIåˆ†æã€‚")
        return

    # 2. è¿æ¥ Telegram
    SESSION_PATH.mkdir(exist_ok=True)  # è‡ªåŠ¨åˆ›å»º sessions ç›®å½•
    client = TelegramClient(
        str(SESSION_PATH / str(api_id)), api_id, api_hash,
        proxy={
            "proxy_type": getattr(socks, proxy_cfg["proxy_type"].upper()),
            "addr": proxy_cfg["addr"],
            "port": proxy_cfg["port"],
            "rdns": proxy_cfg["rdns"],
        } if proxy_cfg else None,
    )
    
    all_messages_text_parts = []
    total_limit = 20000
    limit_per_channel = total_limit // len(channel_usernames) if channel_usernames else total_limit

    async with client:
        logger.info(f"æ­£åœ¨è¿æ¥ Telegram å¹¶ä» {len(channel_usernames)} ä¸ªé¢‘é“è·å–æœ€è¿‘çš„æ¶ˆæ¯...")
        for channel_username in channel_usernames:
            channel_text = ""
            try:
                logger.info(f"  -> æ­£åœ¨ä» @{channel_username} è·å–æ¶ˆæ¯...")
                messages = await client.get_messages(channel_username, limit=100)
                for msg in messages:
                    if msg and msg.text:
                        clean_text = re.sub(r'https?://\S+', '', msg.text)
                        clean_text = re.sub(r'[@#\[\]\(\)\{\}]', '', clean_text)
                        channel_text += clean_text + "\n\n"
                
                # å¯¹æ¯ä¸ªé¢‘é“çš„æ–‡æœ¬ç‹¬ç«‹è¿›è¡Œæˆªæ–­
                all_messages_text_parts.append(channel_text[:limit_per_channel])

            except Exception as e:
                logger.error(f"  -> ä» @{channel_username} è·å–æ¶ˆæ¯å¤±è´¥: {e}")
                continue
    
    all_messages_text = "".join(all_messages_text_parts)

    if not all_messages_text.strip():
        logger.error("âŒ æœªèƒ½ä»ä»»ä½•é¢‘é“è·å–åˆ°æœ‰æ•ˆæ–‡æœ¬æ¶ˆæ¯ï¼Œæ— æ³•è¿›è¡Œåˆ†æã€‚")
        return

    logger.info("âœ… æ¶ˆæ¯è·å–å®Œæ¯•ï¼Œæ­£åœ¨è¯·æ±‚AIè¿›è¡Œæ·±åº¦ä¸»é¢˜åˆ†æï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼‰...")

    # 3. AI æ·±åº¦ä¸»é¢˜åˆ†æ (ä¸“å®¶çº§Prompt v2)
    analysis_prompt = (
        "ä½ æ˜¯ä¸€ä½é¡¶çº§çš„ç§‘æŠ€æ–°é—»åˆ†æå¸ˆï¼Œä»»åŠ¡æ˜¯ä¸ºä¸€ä½æŒ‘å‰”çš„ä¸»ç¼–åˆ¶å®šå†…å®¹ç­›é€‰è§„åˆ™ã€‚è¯·åˆ†æä»¥ä¸‹æ–°é—»æ–‡æœ¬é›†åˆã€‚\n\n"
        "ç¬¬ä¸€æ­¥ï¼šæ€è€ƒè¿‡ç¨‹ (Chain of Thought)\n"
        "è¯·å…ˆåœ¨è„‘æµ·ä¸­ï¼ˆä¸éœ€è¦åœ¨æœ€ç»ˆè¾“å‡ºä¸­å±•ç¤ºï¼‰æ€è€ƒå¹¶è¯†åˆ«å‡ºæ–‡æœ¬ä¸­çš„ä¸»è¦å†…å®¹æ¨¡å¼ã€‚å“ªäº›æ˜¯åå¤å‡ºç°çš„ç¡¬æ ¸æŠ€æœ¯è¯é¢˜ï¼Ÿå“ªäº›æ˜¯ä½ä»·å€¼çš„è¥é”€ä¿¡æ¯æˆ–å¿«è®¯ï¼Ÿå“ªäº›æ˜¯è¾¹ç¼˜è¯é¢˜ï¼Ÿ\n\n"
        "ç¬¬äºŒæ­¥ï¼šæå–æ ¸å¿ƒä¸»é¢˜\n"
        "1.  **æ­£é¢ä¸»é¢˜ (Positive Themes)**: è¯†åˆ«å¹¶åˆ—å‡º 5-7ä¸ªæœ€æ ¸å¿ƒçš„ã€å…·æœ‰æ·±åº¦å’Œä»·å€¼çš„**ç¡¬æ ¸æŠ€æœ¯ä¸»é¢˜**ã€‚ä¾‹å¦‚ï¼š`AIç®—æ³•çªç ´`, `æ“ä½œç³»ç»Ÿå†…æ ¸æ›´æ–°`, `æ–°å‹èŠ¯ç‰‡æ¶æ„`, `å¼€æºé¡¹ç›®é‡å¤§å‘å¸ƒ`ã€‚\n"
        "2.  **è´Ÿé¢ä¸»é¢˜ (Negative Themes)**: è¯†åˆ«å¹¶åˆ—å‡º 5-7ä¸ªåº”è¯¥è¢«**ä¸»åŠ¨è¿‡æ»¤**çš„ä½ä»·å€¼æˆ–æ— å…³ä¸»é¢˜ã€‚ä¾‹å¦‚ï¼š`å…¬å¸å¸¸è§„è´¢æŠ¥`, `é«˜ç®¡äººäº‹å˜åŠ¨`, `äº§å“å¸‚åœºæ¨å¹¿`, `æ— å®è´¨å†…å®¹çš„å¤§ä¼šé¢„å‘Š`ã€‚\n\n"
        "ä¸€äº›æç¤ºã€‚æ¯”å¦‚ä¸€ä¸ªå¥½çš„è§„åˆ™ä¼šåƒè¿™æ ·ï¼š\"ç­›é€‰æ ‡å‡†ï¼šå†…å®¹åº”èšç„¦äºAIã€èŠ¯ç‰‡ã€æ“ä½œç³»ç»Ÿã€å¼€æºé¡¹ç›®ã€ç¼–ç¨‹è¯­è¨€ã€ç½‘ç»œå®‰å…¨ç­‰ç¡¬æ ¸æŠ€æœ¯é¢†åŸŸã€‚\" (æ³¨æ„: æœ€ç»ˆçš„æ ¸å¿ƒæŒ‡ä»¤åªä¼šåŒ…å«æ­£é¢ä¸»é¢˜ï¼Œè´Ÿé¢ä¸»é¢˜ä»…ç”¨äºåç»­çš„ç”¨æˆ·åå¥½é€‰æ‹©)"
        "ç¬¬ä¸‰æ­¥ï¼šå½’çº³ä¸æ³›åŒ– (Summarize and Generalize)\n"
        "ç°åœ¨ï¼Œå›é¡¾ä½ åœ¨ç¬¬äºŒæ­¥ä¸­åˆ—å‡ºçš„ã€æ­£é¢ä¸»é¢˜ã€‘å’Œã€è´Ÿé¢ä¸»é¢˜ã€‘ã€‚å°†å®ƒä»¬åˆ†åˆ«å½’çº³å’Œæç‚¼æˆ **3-5ä¸ªæ›´å®è§‚ã€æ›´å…·ä»£è¡¨æ€§çš„ä¸Šä½æ¦‚å¿µ**ã€‚ä¾‹å¦‚ï¼Œå¦‚æœå…·ä½“ä¸»é¢˜æ˜¯'AIç®—æ³•çªç ´'å’Œ'AIç¡¬ä»¶å‘å¸ƒ'ï¼Œä½ åº”è¯¥å°†å®ƒä»¬å½’çº³ä¸º'äººå·¥æ™ºèƒ½'ã€‚ç›®æ ‡æ˜¯ç”Ÿæˆä¸€ä¸ªæ—¢èƒ½è¦†ç›–å½“å‰å†…å®¹ï¼Œåˆå¯¹æœªæ¥æ–°è¯é¢˜æœ‰åŒ…å®¹æ€§çš„åˆ†ç±»ã€‚\n\n"
        "**ã€é‡è¦ç¦ä»¤ã€‘**: åœ¨æœ€ç»ˆè¾“å‡ºçš„JSONä¸­ï¼Œ`generalized_positive` å’Œ `generalized_negative` çš„å€¼å¿…é¡»æ˜¯ä½ **è‡ªå·±å½’çº³æ€»ç»“å‡ºçš„å®è§‚ç±»åˆ«**ï¼Œç¦æ­¢ç›´æ¥ä½¿ç”¨ç¬¬äºŒæ­¥ä¸­è¯†åˆ«å‡ºçš„å…·ä½“ä¸»é¢˜ï¼Œä¹Ÿç¦æ­¢å¤è¿°æˆ‘åœ¨ç¤ºä¾‹ä¸­ç»™å‡ºçš„ä»»ä½•è¯æ±‡ã€‚\n\n"
        "ç¬¬å››æ­¥ï¼šè¾“å‡ºç»“æœ\n"
        "ä½ çš„æœ€ç»ˆå›ç­”**å¿…é¡»**æ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼Œä¸¥æ ¼éµå¾ªä»¥ä¸‹æ ¼å¼ï¼Œä¸è¦æ·»åŠ ä»»ä½•é¢å¤–çš„è§£é‡Šï¼š\n"
        "```json\n"
        "{\n"
        "  \"generalized_positive\": [\"å®è§‚ä¸»é¢˜1\", \"å®è§‚ä¸»é¢˜2\", ...],\n"
        "  \"generalized_negative\": [\"å®è§‚ä¸»é¢˜A\", \"å®è§‚ä¸»é¢˜B\", ...]\n"
        "}\n"
        "```"
        f"\n\nã€å¾…åˆ†æçš„æ–‡æœ¬ã€‘:\n---\n{all_messages_text}\n---"
    )
    
    analysis_payload = {
        "messages": [{"role": "user", "content": analysis_prompt}],
        "temperature": 0.7,
        "response_format": {"type": "json_object"},
    }

    if config.get("debug"):
        logger.info("--- DEBUG: Full analysis prompt being sent to AI ---")
        # å°†å®Œæ•´çš„promptå†™å…¥ä¸€ä¸ªæ–‡ä»¶ï¼Œæ–¹ä¾¿æŸ¥çœ‹
        debug_prompt_path = SCRIPT_DIR / "debug_prompt.txt"
        with open(debug_prompt_path, "w", encoding="utf-8") as f:
            f.write(analysis_prompt)
        logger.info(f"å®Œæ•´çš„åˆ†ææŒ‡ä»¤å·²ä¿å­˜åˆ°: {debug_prompt_path}")
        logger.info("--- END DEBUG ---")

    response_data = {}
    try:
        # æ˜ç¡®æŒ‡å®šä»»åŠ¡ç±»å‹ä¸º "analysis_and_refinement"
        response = llm_filter._call_llm("analysis_and_refinement", analysis_payload)
        content = response["choices"][0]["message"]["content"]
        response_data = json.loads(content)
        # æ›´æ–°é”®ä»¥åŒ¹é…æ–°çš„Prompt
        positive_themes = response_data.get("generalized_positive", [])
        negative_themes = response_data.get("generalized_negative", [])
    except (Exception, KeyError, IndexError, json.JSONDecodeError) as e:
        logger.error(f"âŒ AIæ·±åº¦åˆ†æå¤±è´¥: {e}\n   LLMåŸå§‹è¿”å›: {response.get('error', response)}")
        return

    if not positive_themes:
        logger.error("âŒ AIæœªèƒ½åˆ†æå‡ºæœ‰æ•ˆçš„ä¸»é¢˜ã€‚")
        return

    # 4. ç”Ÿæˆå¹¶ç¡®è®¤ Base Prompt (V2 - æ›´çµæ´»çš„æŒ‡ä»¤)
    base_prompt_template = (
        "ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘æŠ€æ–°é—»ç¼–è¾‘ï¼Œè´Ÿè´£ç­›é€‰é«˜è´¨é‡ã€ä¿¡æ¯å¯†åº¦å¤§çš„å‰æ²¿æŠ€æœ¯æ–°é—»è¿›è¡Œè½¬å‘ã€‚"
        "ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯è¯†åˆ«å¹¶è½¬å‘ä¸ä»¥ä¸‹é¢†åŸŸé«˜åº¦ç›¸å…³çš„ã€å…·æœ‰æ·±åº¦ä»·å€¼çš„ç¡¬æ ¸æŠ€æœ¯æ–°é—»ï¼š{positive}ã€‚"
        "å¯¹äºä¸åœ¨æ­¤åˆ—è¡¨ä½†ä½ åˆ¤æ–­åŒæ ·å…·æœ‰é«˜æŠ€æœ¯ä»·å€¼çš„æ–°é—»ï¼Œä¹Ÿåº”è€ƒè™‘è½¬å‘ã€‚"
        "ä½ éœ€è¦å‚è€ƒæœ€è¿‘å·²è½¬å‘çš„æ–°é—»æ‘˜è¦ï¼Œå¦‚æœæ–°æ¶ˆæ¯ä¸å®ƒä»¬å†…å®¹é«˜åº¦ç›¸ä¼¼æˆ–é‡å¤ï¼Œåˆ™åˆ¤å®šä¸ºé‡å¤ï¼Œä¸äºˆè½¬å‘ã€‚"
    )
    
    new_base_prompt = base_prompt_template.format(
        positive='ã€'.join(positive_themes)
    )

    logger.info("\n" + "="*20 + " æ­¥éª¤ 1/2: æ ¸å¿ƒæŒ‡ä»¤ç¡®è®¤ " + "="*20)
    logger.info("AIæ ¹æ®æ‚¨çš„é¢‘é“å†…å®¹ï¼Œä¸ºæ‚¨è‡ªåŠ¨ç”Ÿæˆäº†ä»¥ä¸‹æ ¸å¿ƒæŒ‡ä»¤ (base_prompt):")
    
    current_base_prompt = new_base_prompt

    while True:
        print(f"\nã€å½“å‰ç‰ˆæœ¬ã€‘:\n{current_base_prompt}\n")
        confirm_base = input("â” æ˜¯å¦æ¥å—æ­¤æ ¸å¿ƒæŒ‡ä»¤ï¼Ÿ(y/n/e/d - æ¥å—/æ‹’ç»/ç¼–è¾‘/ä¸AIå¯¹è¯å¾®è°ƒ): ").lower()
        
        if confirm_base == 'y':
            config["llm_filter"]["base_prompt"] = current_base_prompt
            logger.info("âœ… æ ¸å¿ƒæŒ‡ä»¤å·²æ›´æ–°ã€‚")
            break
        elif confirm_base == 'n':
            logger.info("â„¹ï¸ å·²ä¿ç•™æ—§çš„æ ¸å¿ƒæŒ‡ä»¤ã€‚")
            break
        elif confirm_base == 'e':
            logger.info("âœï¸ è¯·ç²˜è´´æ‚¨çš„æ–°ç‰ˆæ ¸å¿ƒæŒ‡ä»¤ï¼Œç„¶åæŒ‰ä¸¤æ¬¡å›è½¦é”®ç»“æŸè¾“å…¥:")
            edited_prompt = []
            while True:
                line = input()
                if not line: break
                edited_prompt.append(line)
            current_base_prompt = "\n".join(edited_prompt)
            config["llm_filter"]["base_prompt"] = current_base_prompt
            logger.info("âœ… æ ¸å¿ƒæŒ‡ä»¤å·²é€šè¿‡æ‰‹åŠ¨ç¼–è¾‘æ›´æ–°ã€‚")
            break
        elif confirm_base == 'd':
            feedback = input("âœï¸ è¯·è¾“å…¥æ‚¨çš„ä¿®æ”¹æ„è§: ")
            if not feedback:
                continue

            logger.info("ğŸ¤– æ­£åœ¨è¯·æ±‚AIæ ¹æ®æ‚¨çš„æ„è§è¿›è¡Œå¾®è°ƒ...")

            positive_match = re.search(r'ç¡¬æ ¸æŠ€æœ¯æ–°é—»ï¼š(.*?)\ã€‚', current_base_prompt)
            
            current_pos_list = positive_match.group(1).split('ã€') if positive_match else []

            refine_prompt = (
                "ä½ æ˜¯ä¸€ä½ç²¾å‡†çš„æŒ‡ä»¤ç¼–è¾‘å™¨ï¼Œæ­£åœ¨å¸®åŠ©ä¸€ä½ä¸»ç¼–ä¼˜åŒ–å†…å®¹ç­›é€‰è§„åˆ™ã€‚è¿™é¡¹è§„åˆ™ç”±ä¸€ä¸ªã€æ ¸å¿ƒä¸»é¢˜åˆ—è¡¨ã€‘ï¼ˆåº”è¯¥ä¼˜å…ˆå…³æ³¨çš„å†…å®¹ï¼‰æ„æˆã€‚\n\n"
                f"ã€å½“å‰æ ¸å¿ƒä¸»é¢˜åˆ—è¡¨ã€‘:\n{json.dumps(current_pos_list, ensure_ascii=False)}\n\n"
                f"ã€ä¸»ç¼–çš„ä¿®æ”¹æ„è§ã€‘:\n{feedback}\n\n"
                "ã€ä½ çš„ä»»åŠ¡ã€‘:\n"
                "1.  **åˆ†ææ„è§**: ä»”ç»†åˆ†æã€ä¸»ç¼–çš„ä¿®æ”¹æ„è§ã€‘ï¼Œå¯¹ã€æ ¸å¿ƒä¸»é¢˜åˆ—è¡¨ã€‘è¿›è¡Œå¢ã€åˆ ã€æ”¹æ“ä½œã€‚\n"
                "2.  **é‡æ–°ç”Ÿæˆ**: ä½¿ç”¨ä¿®æ”¹åçš„æ–°åˆ—è¡¨ï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ¨¡æ¿é‡æ–°ç”Ÿæˆä¸€ä¸ª**å…¨æ–°çš„ã€å®Œæ•´**çš„è§„åˆ™æ–‡æœ¬ï¼š\n"
                "   `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„ç§‘æŠ€æ–°é—»ç¼–è¾‘...ä½ çš„æ ¸å¿ƒä»»åŠ¡æ˜¯è¯†åˆ«å¹¶è½¬å‘ä¸ä»¥ä¸‹é¢†åŸŸé«˜åº¦ç›¸å…³çš„ã€å…·æœ‰æ·±åº¦ä»·å€¼çš„ç¡¬æ ¸æŠ€æœ¯æ–°é—»ï¼š<æ–°ä¸»é¢˜åˆ—è¡¨>ã€‚å¯¹äºä¸åœ¨æ­¤åˆ—è¡¨ä½†ä½ åˆ¤æ–­åŒæ ·å…·æœ‰é«˜æŠ€æœ¯ä»·å€¼çš„æ–°é—»ï¼Œä¹Ÿåº”è€ƒè™‘è½¬å‘ã€‚ä½ éœ€è¦å‚è€ƒ...é‡å¤ï¼Œä¸äºˆè½¬å‘ã€‚`\n"
                "3.  **ç›´æ¥è¾“å‡º**: ä¸è¦æœ‰å¤šä½™çš„è§£é‡Šæˆ–å®¢å¥—è¯ï¼Œåªè¿”å›ä¼˜åŒ–åçš„è§„åˆ™å…¨æ–‡ã€‚"
            )
            
            refine_payload = {
                "messages": [{"role": "user", "content": refine_prompt}],
                "temperature": 0.3, # Lower temperature for precise editing
            }
            
            try:
                # Use the designated model for this task
                response = llm_filter._call_llm("analysis_and_refinement", refine_payload)
                refined_text = response["choices"][0]["message"]["content"].strip()
                # Clean up potential markdown code blocks from the response
                current_base_prompt = re.sub(r'```(json)?', '', refined_text).strip()

            except (Exception, KeyError, IndexError):
                logger.error("âŒ AIå¾®è°ƒå¤±è´¥ï¼Œè¯·é‡è¯•ã€‚")
        else:
            logger.warning("  -> è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥ y, n, e, æˆ– dã€‚")

    # 5. ç”Ÿæˆå¹¶ç¡®è®¤ç”¨æˆ·åå¥½
    logger.info("\n" + "="*20 + " æ­¥éª¤ 2/2: ç”¨æˆ·åå¥½é€‰æ‹© " + "="*20)
    logger.info("ç°åœ¨ï¼Œè¯·ä»AIå½’çº³å‡ºçš„å®è§‚ä¸»é¢˜ä¸­ï¼Œé€‰æ‹©æ‚¨ä¸ªäººç‰¹åˆ«å–œæ¬¢æˆ–ä¸å–œæ¬¢çš„ç±»åˆ«ã€‚")
    for i, cat in enumerate(positive_themes, 1):
        print(f"  {i}: {cat}")
    
    def get_user_choices(prompt_text: str) -> List[str]:
        while True:
            try:
                raw_input = input(prompt_text)
                if not raw_input: return []
                indices = [int(i.strip()) for i in raw_input.split(',')]
                return [positive_themes[i-1] for i in indices if 0 < i <= len(positive_themes)]
            except (ValueError, IndexError):
                logger.warning("  -> è¾“å…¥æ— æ•ˆï¼Œè¯·è¾“å…¥æ­£ç¡®çš„æ•°å­—ç¼–å·ï¼Œå¹¶ç”¨é€—å·éš”å¼€ã€‚")

    liked_cats = get_user_choices("\nğŸ‘‰ è¯·è¾“å…¥æ‚¨å–œæ¬¢çš„ç±»åˆ«ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·éš”å¼€ï¼Œå¯è·³è¿‡ï¼‰: ")
    disliked_cats = get_user_choices("ğŸ‘‰ è¯·è¾“å…¥æ‚¨ä¸å–œæ¬¢çš„ç±»åˆ«ç¼–å·ï¼ˆå¤šä¸ªç”¨é€—å·éš”å¼€ï¼Œå¯è·³è¿‡ï¼‰: ")

    like_prompt = f"æˆ‘ç‰¹åˆ«å–œæ¬¢å…³äº{ 'ã€'.join(liked_cats) }çš„æ–°é—»ã€‚" if liked_cats else ""
    dislike_prompt = f"æˆ‘ä¸å–œæ¬¢å…³äº{ 'ã€'.join(disliked_cats) }çš„æ–°é—»ã€‚" if disliked_cats else ""
    config["llm_filter"]["user_like_prompt"] = like_prompt
    config["llm_filter"]["user_dislike_prompt"] = dislike_prompt

    logger.info("\nâœ… å·²æ ¹æ®æ‚¨çš„é€‰æ‹©ç”Ÿæˆä¸ªäººåå¥½ï¼š")
    print(f"  ğŸ‘ å–œæ¬¢: {like_prompt if like_prompt else 'æ— '}")
    print(f"  ğŸ‘ ä¸å–œæ¬¢: {dislike_prompt if dislike_prompt else 'æ— '}")
    
    # 6. ä¿å­˜æœ€ç»ˆé…ç½®
    with open(CONFIG_PATH, "w", encoding="utf-8") as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    logger.info("\nğŸ‰ å…¨éƒ¨é…ç½®å·²æˆåŠŸæ›´æ–°åˆ° config.jsonï¼ç°åœ¨æ‚¨å¯ä»¥è¿è¡Œ main.py äº†ã€‚")


if __name__ == "__main__":
    asyncio.run(generate_prompts())
